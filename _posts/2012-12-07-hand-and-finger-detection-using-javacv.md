---
id: 82
title: Hand and Finger Detection using JavaCV
date: 2012-12-07T09:00:00+00:00
author: gpanther
layout: post
guid: http://www.javaadvent.com/2012/12/hand-and-finger-detection-using-javacv/
permalink: /2012/12/hand-and-finger-detection-using-javacv.html
blogger_blog:
  - www.javaadvent.com
blogger_author:
  - Attila-Mihaly Balazs
blogger_permalink:
  - /2012/12/hand-and-finger-detection-using-javacv.html
blogger_internal:
  - /feeds/2481158163384033132/posts/default/2069329634325850270
dsq_thread_id:
  - 4962579222
categories:
  - 2012
---
<p><em>This post is part of a series on <a href="http://fivedots.coe.psu.ac.th/~ad/jg/">Natural User Interfaces (NUIs)</a> published by Dr. Andrew Davison and deals with detecting hands from a webcam video feed using <a href="https://code.google.com/p/javacv/">JavaCV</a>.</em></p> <p>Note: all the source code for this chapter is available for download from <a href="http://fivedots.coe.psu.ac.th/~ad/jg/nui055/">http://fivedots.coe.psu.ac.th/~ad/jg/nui055/</a></p> <p>The colored blob detection code of chapter 5 (available at <a href="http://fivedots.coe.psu.ac.th/~ad/jg/nui05/">http://fivedots.coe.psu.ac.th/~ad/jg/nui05/</a>) can be used as the basis of other shape analyzers, which I'll illustrate here by extending it to detect a hand and fingers. In Figure 1, I'm wearing a black glove on my left hand. My Handy application attempts to find and label the thumb, index, middle, ring, and little finger. Yellow lines are drawn between the fingertips and the center-of-gravity (COG) of the hand.</p> <div style="clear: both; text-align: center;"><img border="0" height="252" width="320" src="http://4.bp.blogspot.com/-DN5NiI2KIhI/UMD6PTB07OI/AAAAAAAAFlA/ZsW1kzptXuE/s320/image001.png" /><br />Figure 1. Detecting a Left Hand and Fingers.</div> <p>I utilized the HSVSelector application of chapter 5 to determine suitable HSV ranges for the black glove. These ranges are loaded by Handy prior to executing the steps shown in Figure 2 to obtain the hand's contour, its COG, and orientation relative to the horizontal.</p> <div style="clear: both; text-align: center;"><img border="0" height="224" width="320" src="http://3.bp.blogspot.com/-fZ-3OJ6CnpA/UMD6jjn682I/AAAAAAAAFlM/gogxTWVy4-M/s320/image003.png" /><br/>Figure 2. Finding the Hand Contour.</div> <p>The various stages in Figure 2 are almost identical to those carried out by the ColorRectDetector.findRect() method in section 4.1 of chapter 5. However, Handy continues processing, employing a convex hull and convexity defects to locate and label the fingertips within the hand contour. These additional steps are shown in Figure 3.</p> <div style="clear: both; text-align: center;"><img border="0" height="254" width="320" src="http://3.bp.blogspot.com/-B7hU_bqjHZ4/UMD6xmvWP1I/AAAAAAAAFlY/CRQ2UZjObGU/s320/image005.png" /><br/>Figure 3. Finding and Labeling Fingertips.</div> <p>The hull and defects are obtained from the contour with standard OpenCV operations, which I'll explain below. However, the final step of naming the fingers utilizes a rather hacky strategy that assumes the contour's defects are for an out-stretched left hand. The thumb and index finger are located based on their angular position relative to the COG, and the other fingers are identified based on their position relative to those fingers. This process is rather fragile, and can easily become confused, as shown in Figure 4.</p> <div style="clear: both; text-align: center;"><img border="0" height="252" width="320" src="http://1.bp.blogspot.com/-vQWPqhIq-04/UMD7BEyes8I/AAAAAAAAFlk/1NFBKW3Gd9A/s320/image007.png" /><br/>Figure 4. A Misidentified Middle Finger.</div> <p>Nevertheless, the technique is fairly reliable, usually identifying at least the thumb and index finger irrespective of the hand's orientation, which should be enough for basic gesture processing. However, the application doesn't identify gestures, which will hopefully be the subject of a later chapter.</p> <p>Class diagrams for Handy are shown in Figure 5, with only the public methods listed.</p> <div style="clear: both; text-align: center;"><img border="0" height="312" width="320" src="http://1.bp.blogspot.com/-2kBuXNNLDIE/UMD7NyNDVVI/AAAAAAAAFlw/NUr8Da9xm0k/s320/image009.png" /><br />Figure 5. Class Diagrams for Handy.</div> <p>The top-levels of Handy parallel those of the BlobsDrumming application in chapter 5 (e.g. see chapter 5's Figure 11), with the Handy class managing the JFrame and HandPanel displaying the annotated webcam image. The image analyses summarized in Figures 2 and 3 are performed by the HandDetector class, which is passed the current webcam snap via a call to update(). It draws the current labeled fingertips, COG, and connecting lines when HandPanel calls HandDetector.draw().</p> <h2>1. Analyzing the Webcam Image</h2> <p>The update() method is essentially a series of calls that implement Figures 2 and 3.</p> <pre><code><br />// globals<br />private static final int IMG_SCALE = 2; <br />         // scaling applied to webcam image<br /><br />// HSV ranges defining the glove color<br />private int hueLower, hueUpper, satLower, satUpper,<br />            briLower, briUpper;<br /><br />// OpenCV elements<br />private IplImage hsvImg;  // HSV version of webcam image<br />private IplImage imgThreshed;  // threshold for HSV settings<br /><br />// hand details<br />private Point cogPt;       // center of gravity (COG) of contour<br />private int contourAxisAngle;     <br />   // contour's main axis angle relative to the horiz (in degrees)<br />private ArrayList<point> fingerTips;<br /><br /><br />public void update(BufferedImage im)<br />{<br />  BufferedImage scaleIm = scaleImage(im, IMG_SCALE);   <br />      // reduce the size of the image to make processing faster<br /><br />  // convert image format to HSV<br />  cvCvtColor(IplImage.createFrom(scaleIm), hsvImg, CV_BGR2HSV);<br /><br />  // threshold image using loaded HSV settings for user's glove<br />  cvInRangeS(hsvImg, cvScalar(hueLower, satLower, briLower, 0),<br />                     cvScalar(hueUpper, satUpper, briUpper, 0),<br />                        imgThreshed);<br /><br />  cvMorphologyEx(imgThreshed, imgThreshed, null, null,<br />                                             CV_MOP_OPEN, 1);<br />     // erosion followed by dilation on the image to remove<br />     // specks of white while retaining the image size<br /><br />  CvSeq bigContour = <b>findBiggestContour</b>(imgThreshed);<br />  if (bigContour == null)<br />    return;<br /><br />  <b>extractContourInfo</b>(bigContour, IMG_SCALE);<br />     // find the COG and angle to horizontal of the contour<br /><br />  <b>findFingerTips</b>(bigContour, IMG_SCALE);<br />      // detect the fingertips positions in the contour<br /><br />  <b>nameFingers</b>(cogPt, contourAxisAngle, fingerTips);<br />}  // end of update()<br /></code></pre> <p>update() begins by scaling the supplied webcam image to improve processing speeds. It then converts the picture into HSV format so it can generate a threshold image using the black glove's HSV ranges. This corresponds to the first line of Figure 2, although the threshold is actually rendered as white pixels against a black background.</p> <p>The threshold, minus small specks, is passed to findBiggestContour(); the resulting contour is assumed to be the user's hand in subsequent processing stages. extractContourInfo() analyzes the contour to find the hand's center-of-gravity (COG), and its orientation relative to the horizontal, which are stored in the cogPt and contourAxisAngle globals. The completion of extractContourInfo() corresponds to the end of Figure 2.</p> <p>The findFingerTips() method wraps a convex hull around the contour to identify the shape's defects (the top line of Figure 3), which we assume are the hand's fingers. After a little filtering to reduce the number of defects, the remaining ones are treated as fingertip coordinates, and stored in the global fingerTips list.</p> <p>nameFingers() labels the fingers (assuming that the thumb and index finger are on the left side of the hand), completing Figure 3's stages.</p> <h2>1.1  Finding the Biggest Contour</h2> <p>findBiggestContour() uses the OpenCV function cvFindContours() to create a list of contours. For my binary threshold image, a contour is a region (or blob) of white pixels. Each blob is approximated by a bounding box, and the contour corresponding to the largest box is selected and returned.</p> <pre><code><br />// globals<br />private static final float SMALLEST_AREA = 600.0f;<br />            // ignore smaller contour areas<br /><br />private CvMemStorage contourStorage;<br /><br /><br />private CvSeq findBiggestContour(IplImage imgThreshed)<br />{<br />  CvSeq bigContour = null;<br />  // generate all the contours in the threshold image as a list<br />  CvSeq contours = new CvSeq(null);<br />  cvFindContours(imgThreshed, contourStorage, contours,<br />                          Loader.sizeof(CvContour.class),<br />                          CV_RETR_LIST, CV_CHAIN_APPROX_SIMPLE);<br /><br />  // find the largest contour in the list based on bounded box size<br />  float maxArea = SMALLEST_AREA;<br />  CvBox2D maxBox = null;<br />  while (contours != null && !contours.isNull()) {<br />    if (contours.elem_size() > 0) {<br />      CvBox2D box = cvMinAreaRect2(contours, contourStorage);<br />      if (box != null) {<br />        CvSize2D32f size = box.size();<br />        float area = size.width() * size.height();<br />        if (area > maxArea) {<br />          maxArea = area;<br />          bigContour = contours;<br />        }<br />      }<br />    }<br />    contours = contours.h_next();<br />  }<br />  return bigContour;<br />}  // end of findBiggestContour()<br /></code></pre> <p>cvFindContours() can return different types of contours, collected together in different kinds of data structures. I generate the simplest kind of contours, storing them in a linear list which can be searched with a while loop.</p> <p>After some experimentation, I placed a lower bound on the bounded box size of 600 square pixels which filters out small boxes surrounding patches of image noise. This means that findBiggestContour() may return null if it doesn’t find a large enough box.</p> <h2>1.2 Calculating the COG and Horizontal Angle</h2> <p>The next step shown in Figure 2 is to find the COG and angle to the horizontal of the hand contour by calling extractContourInfo(). This is where the code in HandDetector starts to part company from the analysis carried out by ColorRectDetector.findRect() in chapter 5. In section 4.2 of that chapter, the enclosing box around the contour is utilized to obtain a center and orientation. This is adequate because the underlying shape is a rectangular card, and so the contour and box are almost identical. However, a bounding box around a hand can easily have a very different COG or angle from the hand itself; in this case, it's necessary to directly analyze the hand contour rather than a bounding box, by utilizing moments.</p> <p>I used spatial moments back in chapter 3 to find the COG of a binary image. The same technique can be applied to a contour to find its center (or centroid). I can also calculate second order mixed moments, which give information about the spread of pixels around the centroid. Second order moments can be combined to return the orientation (or angle) of the contour’s major axis relative to the x-axis.</p> <p>Referring back to the OpenCV moments notation from chapter 3, the m() moments function is defined as:</p> <div style="clear: both; text-align: center;"><img border="0" height="26" width="224" src="http://3.bp.blogspot.com/-fgVpWSfXNhA/UMD8t6hx-cI/AAAAAAAAFl8/BH0nJ--MBlk/s320/image012.png" /></div> <p>The function takes two arguments, p and q, which are used as powers for x and y. The I() function is the intensity for a pixel defined by its (x, y) coordinate. n is the number of pixels that make up the shape.</p> <p>If I consider a contour like the one in Figure 6, then θ is the angle of its major axis to the horizontal, with the +y-axis pointing downwards.</p> <div style="clear: both; text-align: center;"><img border="0" height="272" width="320" src="http://2.bp.blogspot.com/-h-_wMc-Q0Zo/UMD8_dWWjLI/AAAAAAAAFmI/ec_XJZspcKY/s320/image013.png" /><br />Figure 6. A Contour and its Major Axis Line.</div> <p>In terms of the m() function, it can be shown that:</p> <div style="clear: both; text-align: center;"><img border="0" height="37" width="181" src="http://4.bp.blogspot.com/-wRCGLR_DcHI/UMD9TZ2QL5I/AAAAAAAAFmU/C-NMi53q5Bo/s320/image016.png" /></div> <p>The extractContourInfo() method shown below uses spatial moments to obtain the contour’s centroid, and cvGetCentralMoment() to calculate the major axis angle according to the above equation; these results are stored in the globals cogPt and contourAxisAngle for use later.</p> <pre><code><br />// globals<br />private Point cogPt;       // center of gravity (COG) of contour<br />private int contourAxisAngle;     <br />     // contour's main axis angle relative to horizontal (in degrees)<br /><br />private ArrayList<point> fingerTips;<br /><br /><br />private void extractContourInfo(CvSeq bigContour, int scale)<br />{<br />  CvMoments moments = new CvMoments();<br />  cvMoments(bigContour, moments, 1);<br /><br />  // center of gravity<br />  double m00 = cvGetSpatialMoment(moments, 0, 0) ;<br />  double m10 = cvGetSpatialMoment(moments, 1, 0) ;<br />  double m01 = cvGetSpatialMoment(moments, 0, 1);<br /><br />  if (m00 != 0) {   // calculate center<br />    int xCenter = (int) Math.round(m10/m00)*scale;<br />    int yCenter = (int) Math.round(m01/m00)*scale;<br />    cogPt.setLocation(xCenter, yCenter);<br />  }<br /><br />  double m11 = cvGetCentralMoment(moments, 1, 1);<br />  double m20 = cvGetCentralMoment(moments, 2, 0);<br />  double m02 = cvGetCentralMoment(moments, 0, 2);<br />  contourAxisAngle = calculateTilt(m11, m20, m02);<br /><br />  // deal with hand contour pointing downwards<br />  /* uses fingertips information generated on the last update of<br />     the hand, so will be out-of-date */<br /><br />  if (fingerTips.size() > 0) {<br />    int yTotal = 0;<br />    for(Point pt : fingerTips)<br />      yTotal += pt.y;<br />    int avgYFinger = yTotal/fingerTips.size();<br />    if (avgYFinger > cogPt.y)   // fingers below COG<br />      contourAxisAngle += 180;<br />  }<br />  contourAxisAngle = 180 - contourAxisAngle;  <br />       /* this makes the angle relative to a positive y-axis that<br />          runs up the screen */<br />}  // end of extractContourInfo()<br /><br /><br /><br />private int calculateTilt(double m11, double m20, double m02)<br />{<br />  double diff = m20 - m02;<br />  if (diff == 0) {<br />    if (m11 == 0)<br />      return 0;<br />    else if (m11 > 0)<br />      return 45;<br />    else   // m11 < 0<br />      return -45;<br />  }<br /><br />  double theta = 0.5 * Math.atan2(2*m11, diff);<br />  int tilt = (int) Math.round( Math.toDegrees(theta));<br /><br />  if ((diff > 0) && (m11 == 0))<br />    return 0;<br />  else if ((diff < 0) && (m11 == 0))<br />    return -90;<br />  else if ((diff > 0) && (m11 > 0))  // 0 to 45 degrees<br />    return tilt;<br />  else if ((diff > 0) && (m11 < 0))  // -45 to 0<br />    return (180 + tilt);   // change to counter-clockwise angle<br />  else if ((diff < 0) && (m11 > 0))   // 45 to 90<br />    return tilt;<br />  else if ((diff < 0) && (m11 < 0))   // -90 to -45<br />    return (180 + tilt);  // change to counter-clockwise angle<br /><br />  System.out.println("Error in moments for tilt angle");<br />  return 0;<br />}  // end of calculateTilt()<br /></code></pre> <p>Moments in OpenCV are explained in depth in "Simple Image Analysis by Moments" by Johannes Kilian at <a href="http://public.cranfield.ac.uk/c5354/teaching/dip/opencv/SimpleImageAnalysisbyMoments.pdf">http://public.cranfield.ac.uk/c5354/teaching/dip/opencv/SimpleImageAnalysisbyMoments.pdf</a>. The code inside calculateTilt() is based on the special cases for θ listed in Table 1 of Kilian's paper.</p> <p>Unfortunately, the axis angle doesn't distinguish between a hand with fingers pointing upwards and one facing down, and so it's necessary to examine the relative position of the fingertips with respect to the COG to decide whether the angle should be adjusted. The problem is that this information isn't available until after the hand contour's convex hull has been examined for defects, which occurs after extractContourInfo() has finished.</p> <p>My solution is to use the fingertip coordinates calculated in the previous call to update() which analyzed the webcam frame before the current one. The data will be out-of-date, but the hand won't have moved much in the 200 ms interval between snaps.</p> <h2>1.3 Finding the Fingertips</h2> <p>Identifying the fingertips is carried out in the first row of Figure 3; in the code, a convex hull is wrapped around the contour by OpenCV's cvConvexHull2() and this polygon is compared to the contour by cvConvexityDefects() to find its defects.</p> <p>Hull creation and defect analysis are speeded up by utilizing a low-polygon approximation of the contour rather than the original.</p> <p>These stages are performed in the first half of the findFingerTips() method:</p> <pre><code><br />// globals<br />private static final int MAX_POINTS = 20;  <br />               // max number of points stored in an array<br /><br />// OpenCV elements<br />private CvMemStorage contourStorage, approxStorage,<br />                     hullStorage, defectsStorage;<br /><br />// defects data for the hand contour<br />private Point[] tipPts, foldPts;   <br />private float[] depths;<br /><br /><br />private void findFingerTips(CvSeq bigContour, int scale)<br />{<br />  CvSeq approxContour = cvApproxPoly(bigContour,<br />                 Loader.sizeof(CvContour.class),<br />                 approxStorage, CV_POLY_APPROX_DP, 3, 1);<br />     // reduce number of points in the contour<br /><br />  CvSeq hullSeq = cvConvexHull2(approxContour,<br />                    hullStorage, CV_COUNTER_CLOCKWISE, 0);<br />     // find the convex hull around the contour<br /><br />  CvSeq defects = cvConvexityDefects(approxContour,<br />                                 hullSeq, defectsStorage);<br />     // find the defect differences between the contour and hull<br /><br />  int defectsTotal = defects.total();<br />  if (defectsTotal > MAX_POINTS) {<br />    System.out.println("Processing " + MAX_POINTS + " defect pts");<br />    defectsTotal = MAX_POINTS;<br />  }<br /><br />  // copy defect information from defects sequence into arrays<br />  for (int i = 0; i < defectsTotal; i++) {<br />    Pointer pntr = cvGetSeqElem(defects, i);<br />    CvConvexityDefect cdf = new CvConvexityDefect(pntr);<br /><br />    CvPoint startPt = cdf.start();<br />    tipPts[i] = new Point( (int)Math.round(startPt.x()*scale),<br />                              (int)Math.round(startPt.y()*scale));<br />      // array contains coords of the fingertips<br /><br />    CvPoint endPt = cdf.end();<br />    CvPoint depthPt = cdf.depth_point();<br />    foldPts[i] = new Point( (int)Math.round(depthPt.x()*scale),<br />                              (int)Math.round(depthPt.y()*scale));<br />        //array contains coords of the skin fold between fingers<br /><br />    depths[i] = cdf.depth()*scale;<br />        // array contains distances from tips to folds<br />  }<br /><br />  <b>reduceTips</b>(defectsTotal, tipPts, foldPts, depths);<br />}  // end of findFingerTips()<br /></code></pre> <p>The latter half of findFingerTips() extracts the tip and fold coordinates and depths from the defects sequence. The earlier call to the convex hull method, cvConvexHull2(), with a CV_COUNTER_CLOCKWISE argument means that the coordinates will be stored in a counter-clockwise order, like that of Figure 7.</p> <div style="clear: both; text-align: center;"><img border="0" height="264" width="320" src="http://3.bp.blogspot.com/-rcs5LQovaH4/UMD_HGkkEgI/AAAAAAAAFmg/4XuBm30lrsE/s320/image017.png" /><br />Figure 7. Fingertips, Folds, and Depths.</div> <p>The fingertips are stored in a tipPts[] array, the finger folds (the indentations between the fingers) in foldPts[], and their depths in depths[].</p> <p>As Figure 7 suggests, the analysis often generates too many defects, and so reduceTips() is called at the end of findFingerTips(). It applies two simple tests to filter out defects that are unlikely to be fingertips – it discards points with shallow defect depths, and coordinates with too great an angle between their neighboring fold points. Examples of both are shown in Figure 8.</p> <div style="clear: both; text-align: center;"><img border="0" height="75" width="320" src="http://4.bp.blogspot.com/-9c5rHUe8xYQ/UMD_WQa0QHI/AAAAAAAAFms/IQ9d3IDshC8/s320/image018.png" /><br />Figure 8. Shallow Depths and Wide Angles.</div> <p>reduceTips() stores the remaining tip points in the global fingerTips list:</p> <pre><code><br /><br />// globals<br />private static final int MIN_FINGER_DEPTH = 20;<br />private static final int MAX_FINGER_ANGLE = 60;   // degrees<br /><br />private ArrayList<point> fingerTips;<br /><br /><br />private void reduceTips(int numPoints, Point[] tipPts,<br />                     Point[] foldPts, float[] depths)<br />{<br />  fingerTips.clear();<br /><br />  for (int i=0; i < numPoints; i++) {<br />    if (depths[i] < MIN_FINGER_DEPTH)    // defect too shallow<br />      continue;<br /><br />    // look at fold points on either side of a tip<br />    int pdx = (i == 0) ? (numPoints-1) : (i - 1); // predecessor of i<br />    int sdx = (i == numPoints-1) ? 0 : (i + 1);   // successor of i<br /><br />    int angle = angleBetween(tipPts[i], foldPts[pdx], foldPts[sdx]);<br />    if (angle >= MAX_FINGER_ANGLE)    <br />      continue;      // angle between finger and folds too wide<br /><br />    // this point is probably a fingertip, so add to list<br />    fingerTips.add(tipPts[i]);<br />  }<br />}  // end of reduceTips()<br /><br /><br />private int angleBetween(Point tip, Point next, Point prev)<br />// calculate the angle between the tip and its neighboring folds<br />// (in integer degrees)<br />{<br />  return Math.abs( (int)Math.round(<br />            Math.toDegrees(<br />                  Math.atan2(next.x - tip.x, next.y - tip.y) -<br />                  Math.atan2(prev.x - tip.x, prev.y - tip.y)) ));<br />}<br /></code></pre> <h2>1.4 Naming the Fingers</h2> <p>nameFingers() uses the list of fingertip coordinates, and the contour's COG and axis angle to label the fingers in two steps. First, it calls labelThumbIndex() to label the thumb and index finger based on their likely angles relative to the COG, assuming that they are on the left side of the hand. nameFingers() attempts to label the other fingers in labelUnknowns(), based on their known order relative to the thumb and index finger.</p> <pre><code><br />// globals<br />private ArrayList<fingerName> namedFingers;<br /><br /><br />private void nameFingers(Point cogPt, int contourAxisAngle,<br />                                   ArrayList<point> fingerTips)<br />{ // reset all named fingers to unknown<br />  namedFingers.clear();<br />  for (int i=0; i < fingerTips.size(); i++)<br />    namedFingers.add(FingerName.UNKNOWN);<br /><br />  labelThumbIndex(fingerTips, namedFingers);<br />  labelUnknowns(namedFingers);<br />}  // end of nameFingers()<br /></code></pre> <p>The Finger IDs and their relative order are maintained in a FingerName enumeration:</p> <pre><code><br />public enum FingerName {<br />   LITTLE, RING, MIDDLE, INDEX, THUMB, UNKNOWN;<br /><br /><br />  public FingerName getNext()<br />  { <br />    int nextIdx = ordinal()+1;<br />    if (nextIdx == (values().length))<br />      nextIdx = 0;<br />    return values()[nextIdx]; <br />  }  // end of getNext()<br /><br /><br />  public FingerName getPrev()<br />  { <br />    int prevIdx = ordinal()-1;<br />    if (prevIdx < 0)<br />      prevIdx = values().length-1;<br />    return values()[prevIdx]; <br />  }  // end of getPrev()<br /><br />}  // end of FingerName enum<br /></code></pre> <p>One of the possible finger names is UNKNOWN, which is used to label all the fingertips prior to the calls to the naming methods.</p> <p>labelThumbIndex() attempts to label the thumb and index fingers based on the angle ranges illustrated in Figure 9.</p> <div style="clear: both; text-align: center;"><img border="0" height="306" width="320" src="http://2.bp.blogspot.com/-WEQKlTjuhNY/UMEALpsA9RI/AAAAAAAAFm4/EXeiIRRPsVM/s320/image019.png" /><br />Figure 9. Angle Ranges for the Thumb and Index Fingers.</div> <p>The index finger can turn between 60 and 120 degrees around the COG, while the thumb can move between 120 and 200 degrees. I arrived at these angles through trial-and-error, and they assume that the hand is orientated straight up.</p> <p>labelThumbIndex() also assumes that the thumb and index fingers will most likely be stored at the end of the fingerTips list, since the contour hull was built in a counter-clockwise order. It therefore increases its chances of matching against the right defects by iterating backwards through the list.</p> <pre><code><br />// globals<br />private static final int MIN_THUMB = 120;  // angle ranges<br />private static final int MAX_THUMB = 200;<br /><br />private static final int MIN_INDEX = 60;<br />private static final int MAX_INDEX = 120;<br /><br />// hand details<br />private Point cogPt<br />private int contourAxisAngle;     <br /><br /><br />private void labelThumbIndex(ArrayList<point> fingerTips,<br />                             ArrayList<fingerName> nms)<br />{<br />  boolean foundThumb = false;<br />  boolean foundIndex = false;<br />  int i = fingerTips.size()-1;<br />  while ((i >= 0)) {<br />    int angle = angleToCOG(fingerTips.get(i),<br />                               cogPt, contourAxisAngle);<br />    // check for thumb<br />    if ((angle <= MAX_THUMB) && (angle>MIN_THUMB) && !foundThumb) {<br />      nms.set(i, FingerName.THUMB);<br />      foundThumb = true;<br />    }<br /><br />    // check for index<br />    if ((angle <= MAX_INDEX) && (angle > MIN_INDEX) && !foundIndex) {<br />      nms.set(i, FingerName.INDEX);<br />       foundIndex = true;<br />    }<br />    i--;<br />  }<br />}  // end of labelThumbIndex()<br /></code></pre> <p>angleToCOG() calculates the angle of a fingertip relative to the COG, remembering to factor in the contour axis angle so that the hand is orientated straight up.</p> <pre><code><br />private int angleToCOG(Point tipPt, Point cogPt,<br />                                     int contourAxisAngle)<br />{<br />  int yOffset = cogPt.y - tipPt.y;    // make y positive up screen<br />  int xOffset = tipPt.x - cogPt.x;<br />  double theta = Math.atan2(yOffset, xOffset);<br />  int angleTip = (int) Math.round( Math.toDegrees(theta));<br />  return angleTip + (90 - contourAxisAngle);<br />           // this ensures that the hand is orientated straight up<br />}  // end of angleToCOG()<br /></code></pre> <p>labelUnknowns() is passed a list of finger names which hopefully contains THUMB and INDEX at certain positions and UNKNOWNs everywhere else. Using a named finger as a starting point, the UNKNOWNs are changed to finger names based on their ordering in the FingerName enumeration.</p> <pre><code><br />private void labelUnknowns(ArrayList<fingerName> nms)<br />{<br />  // find first named finger<br />  int i = 0;<br />  while ((i < nms.size()) && (nms.get(i) == FingerName.UNKNOWN))<br />    i++;<br />  if (i == nms.size())   // no named fingers found, so give up<br />    return;<br /><br />  FingerName name = nms.get(i);<br />  labelPrev(nms, i, name);    // fill-in backwards<br />  labelFwd(nms, i, name);     // fill-in forwards<br />}  // end of labelUnknowns()<br /></code></pre> <p>labelPrev() and labelFwd() differ only in the direction they move through the list of names. labelPrev() moves backwards trying to change UNKNOWNS to named fingers, but only if the name hasn't already been assigned to the list.</p> <h2>2 Drawing the Named Fingers</h2> <p>The analysis performed by update() will result in a list of fingertip points (in the fingerTips global), an associated list of named fingers (in namedFingers), and a contour COG and axis angle. All of these, apart from the angle, are utilized by draw() to add named finger labels to the webcam image, as shown in Figure 1 and Figure 10 below.</p> <div style="clear: both; text-align: center;"><img border="0" height="252" width="320" src="http://4.bp.blogspot.com/-Dw6r20gNIOo/UMEA_WDfWhI/AAAAAAAAFnE/sY4dcG7Wpp0/s320/image020.png" /><br />Figure 10. Named Fingers and an Unknown.</div> <p>An unknown finger 'tip' (labeled as UNKNOWN in namedFingers) is drawn as a red circle.</p> <pre><code><br />// globals<br />private Point cogPt;<br />private ArrayList<point> fingerTips;<br />private ArrayList<fingerName> namedFingers;<br /><br /><br />public void draw(Graphics2D g2d)<br />{<br />  if (fingerTips.size() == 0)<br />    return;<br /><br />  g2d.setRenderingHint(RenderingHints.KEY_ANTIALIASING,<br />          RenderingHints.VALUE_ANTIALIAS_ON);  // line smoothing<br />  g2d.setPaint(Color.YELLOW);<br />  g2d.setStroke(new BasicStroke(4));  // thick yellow pen<br /><br />  // label tips in red or green, and draw lines to named tips<br />  g2d.setFont(msgFont);<br />  for (int i=0; i < fingerTips.size(); i++) {<br />    Point pt = fingerTips.get(i);<br />    if (namedFingers.get(i) == FingerName.UNKNOWN) {<br />      g2d.setPaint(Color.RED);   // unnamed fingertip is red<br />      g2d.drawOval(pt.x-8, pt.y-8, 16, 16);<br />      g2d.drawString("" + i, pt.x, pt.y-10);   // label with a digit<br />    }<br />    else {   // draw yellow line to the named fingertip from COG<br />      g2d.setPaint(Color.YELLOW);<br />      g2d.drawLine(cogPt.x, cogPt.y, pt.x, pt.y);<br /><br />      g2d.setPaint(Color.GREEN);   // named fingertip is green<br />      g2d.drawOval(pt.x-8, pt.y-8, 16, 16);<br />      g2d.drawString(namedFingers.get(i).toString().toLowerCase(),<br />                            pt.x, pt.y-10);<br />    }<br />  }<br /><br />  // draw COG<br />  g2d.setPaint(Color.GREEN);<br />  g2d.fillOval(cogPt.x-8, cogPt.y-8, 16, 16);<br />}  // end of draw()<br /></code></pre> <h2>3 Gesture Detection</h2> <p>The Handy application stops short at converting the named fingertips into gestures, which would require an analysis of how the fingers move through space over time.</p> <p>Preliminary tests show that Handy can only identify gestures reliably when they involve an outstretched thumb and/or index finger, perhaps combined with other fingers. Gestures of this type include "victory", "wave", "good", "point", and "gun" shown in Figure 11.</p> <div style="clear: both; text-align: center;"><img border="0" height="107" width="320" src="http://2.bp.blogspot.com/-G53C2_6lHdc/UMEBWKqy4CI/AAAAAAAAFnQ/pHjuPyBqjU4/s320/image022.png" /><br/>Figure 11. Gestures Suitable for Handy-style Detection.</div> <p>A common gesture that cannot be detected by Handy is "ok" (see Figure 12) because it requires the fingers be brought together, which cannot be detected solely in terms of contour defects.</p> <div style="clear: both; text-align: center;"><img border="0" height="199" width="123" src="http://3.bp.blogspot.com/-pViMs6uJqb8/UMECIMBbUBI/AAAAAAAAFnc/pQW1Y68Taq8/s320/image024.png" /><br/>Figure 12. The Unsuitable "ok" Gesture.</div> <p><em>Meta: this post is part of the <a href="http://javaadvent.com/">Java Advent Calendar</a> and is licensed under the <a href="https://creativecommons.org/licenses/by/3.0/">Creative Commons 3.0 Attribution</a> license. If you like it, please spread the word by sharing, tweeting, FB, G+ and so on! Want to write for the blog? We are looking for contributors to fill all 24 slot and would love to have your contribution! <a href="mailto:dify.ltd@gmail.com">Contact Attila Balazs</a>to contribute!</em></p>